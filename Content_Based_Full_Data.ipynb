{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import pickle\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINAL RESULTS :\n",
    "RMSE on train2 with training on train1 = 2.308427215577763\n",
    "RMSE on test with training on train1+train2 = 2.401714997765819**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out places having a specific Lat-Long range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for index,row in merged_df.iterrows():\n",
    "    if float(row[\"Latitude\"]) > 10**7 or float(row[\"Latitude\"]) < -10**7:\n",
    "        index_list.append(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"/Users/studentuser/Downloads/Project/Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_categories = pd.read_csv(\"places_with_categories.csv\")\n",
    "places_categories.columns = ['gPlusPlaceId', 'name', 'Latitude', 'Longitude', 'categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_reviews.merge(places_categories, on = 'gPlusPlaceId')\n",
    "merged_df = merged_df.dropna(subset=[\"categories_y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since gPlusPlaceId and gPlusUserId are long strings, there was a mapping created to smaller indices which was stored in pickles (new_item.pickle and new_user.pickle)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pickle = open(\"/Users/studentuser/Downloads/Project/pickles/new_item.pickle\",\"rb\")\n",
    "item_dict = pickle.load(item_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pickle = open(\"/Users/studentuser/Downloads/Project/pickles/new_user.pickle\",\"rb\")\n",
    "user_dict = pickle.load(user_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"placeIndex\"] = merged_df[\"gPlusPlaceId\"].apply(lambda x : item_dict[x] if x in item_dict.keys() else None )\n",
    "merged_df[\"userIndex\"] = merged_df[\"gPlusUserId\"].apply(lambda x : user_dict[x] if x in user_dict.keys() else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(subset=['placeIndex', 'userIndex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create two dictionaries** \n",
    "1. One dictionary will be dict[place] = [\"Asian\" , \"Chinese\"]\n",
    "2. Second dictionary will be dict[\"Asian\"] = [\"place1\" , \"place2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_to_cat_pickle = open(\"/Users/studentuser/Downloads/Project/pickles/place_to_cat_new.pickle\",\"rb\")\n",
    "place_to_cat = pickle.load(place_to_cat_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_place_pickle = open(\"/Users/studentuser/Downloads/Project/pickles/cat_to_place_new.pickle\",\"rb\")\n",
    "cat_to_place = pickle.load(cat_to_place_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18798, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>categories_x</th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>gPlusUserId</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>categories_y</th>\n",
       "      <th>placeIndex</th>\n",
       "      <th>userIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>22</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>103133677716773897224</td>\n",
       "      <td>100000039815955317902</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Dec 14, 2012</td>\n",
       "      <td>1.355475e+09</td>\n",
       "      <td>Moirabari Market</td>\n",
       "      <td>26.454098</td>\n",
       "      <td>92.421952</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1329667</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>103133677716773897224</td>\n",
       "      <td>102118273302242190955</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Aug 30, 2012</td>\n",
       "      <td>1.346393e+09</td>\n",
       "      <td>Moirabari Market</td>\n",
       "      <td>26.454098</td>\n",
       "      <td>92.421952</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>974.0</td>\n",
       "      <td>1293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2330330</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>103133677716773897224</td>\n",
       "      <td>103707354936917456863</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Mar 18, 2013</td>\n",
       "      <td>1.363634e+09</td>\n",
       "      <td>Moirabari Market</td>\n",
       "      <td>26.454098</td>\n",
       "      <td>92.421952</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>974.0</td>\n",
       "      <td>2323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8706625</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>103133677716773897224</td>\n",
       "      <td>113956358126441896410</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nov 19, 2012</td>\n",
       "      <td>1.353317e+09</td>\n",
       "      <td>Moirabari Market</td>\n",
       "      <td>26.454098</td>\n",
       "      <td>92.421952</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>974.0</td>\n",
       "      <td>8949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>11171878</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>103133677716773897224</td>\n",
       "      <td>117980982174626534554</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jan 19, 2014</td>\n",
       "      <td>1.390137e+09</td>\n",
       "      <td>Moirabari Market</td>\n",
       "      <td>26.454098</td>\n",
       "      <td>92.421952</td>\n",
       "      <td>[u'Market']</td>\n",
       "      <td>974.0</td>\n",
       "      <td>11452.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 categories_x           gPlusPlaceId            gPlusUserId  \\\n",
       "95          22  [u'Market']  103133677716773897224  100000039815955317902   \n",
       "96     1329667  [u'Market']  103133677716773897224  102118273302242190955   \n",
       "97     2330330  [u'Market']  103133677716773897224  103707354936917456863   \n",
       "98     8706625  [u'Market']  103133677716773897224  113956358126441896410   \n",
       "99    11171878  [u'Market']  103133677716773897224  117980982174626534554   \n",
       "\n",
       "    rating    reviewTime  unixReviewTime              name   Latitude  \\\n",
       "95     4.0  Dec 14, 2012    1.355475e+09  Moirabari Market  26.454098   \n",
       "96     3.0  Aug 30, 2012    1.346393e+09  Moirabari Market  26.454098   \n",
       "97     2.0  Mar 18, 2013    1.363634e+09  Moirabari Market  26.454098   \n",
       "98     3.0  Nov 19, 2012    1.353317e+09  Moirabari Market  26.454098   \n",
       "99     5.0  Jan 19, 2014    1.390137e+09  Moirabari Market  26.454098   \n",
       "\n",
       "    Longitude categories_y  placeIndex  userIndex  \n",
       "95  92.421952  [u'Market']       974.0        0.0  \n",
       "96  92.421952  [u'Market']       974.0     1293.0  \n",
       "97  92.421952  [u'Market']       974.0     2323.0  \n",
       "98  92.421952  [u'Market']       974.0     8949.0  \n",
       "99  92.421952  [u'Market']       974.0    11452.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataframe to store place info with their geolocation and categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>placeIndex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>974.0</th>\n",
       "      <td>26.454098</td>\n",
       "      <td>92.421952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459.0</th>\n",
       "      <td>26.782564</td>\n",
       "      <td>83.409703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204.0</th>\n",
       "      <td>26.484356</td>\n",
       "      <td>90.548533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943.0</th>\n",
       "      <td>27.973463</td>\n",
       "      <td>85.963812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057.0</th>\n",
       "      <td>26.792200</td>\n",
       "      <td>88.448716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Latitude  Longitude\n",
       "placeIndex                      \n",
       "974.0       26.454098  92.421952\n",
       "459.0       26.782564  83.409703\n",
       "2204.0      26.484356  90.548533\n",
       "2943.0      27.973463  85.963812\n",
       "2057.0      26.792200  88.448716"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_geodf = merged_df_final[['placeIndex','Latitude', 'Longitude']].copy()\n",
    "place_geodf = place_geodf.set_index('placeIndex')\n",
    "place_geodf = place_geodf.loc[~place_geodf.index.duplicated(keep='first')]\n",
    "place_geodf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_geodf.to_csv(\"place_geo_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude     26.782564\n",
       "Longitude    83.409703\n",
       "Name: 459.0, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_geodf.loc[459,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>categories_x</th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>gPlusUserId</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>categories_y</th>\n",
       "      <th>placeIndex</th>\n",
       "      <th>userIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8707432</th>\n",
       "      <td>2970481</td>\n",
       "      <td>[u'Hindu Temple']</td>\n",
       "      <td>100699313239966093888</td>\n",
       "      <td>104736345918291046305</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Feb 10, 2013</td>\n",
       "      <td>1.360547e+09</td>\n",
       "      <td>Gokarna Mahadev Temple</td>\n",
       "      <td>27.739403</td>\n",
       "      <td>85.387807</td>\n",
       "      <td>[u'Hindu Temple']</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707433</th>\n",
       "      <td>4078970</td>\n",
       "      <td>[u'Hindu Temple']</td>\n",
       "      <td>100699313239966093888</td>\n",
       "      <td>106516869171611562978</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nov 2, 2013</td>\n",
       "      <td>1.383409e+09</td>\n",
       "      <td>Gokarna Mahadev Temple</td>\n",
       "      <td>27.739403</td>\n",
       "      <td>85.387807</td>\n",
       "      <td>[u'Hindu Temple']</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707434</th>\n",
       "      <td>4399352</td>\n",
       "      <td>[u'Hindu Temple']</td>\n",
       "      <td>100699313239966093888</td>\n",
       "      <td>107033935968639228641</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mar 24, 2013</td>\n",
       "      <td>1.364170e+09</td>\n",
       "      <td>Gokarna Mahadev Temple</td>\n",
       "      <td>27.739403</td>\n",
       "      <td>85.387807</td>\n",
       "      <td>[u'Hindu Temple']</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4477.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       categories_x           gPlusPlaceId  \\\n",
       "8707432     2970481  [u'Hindu Temple']  100699313239966093888   \n",
       "8707433     4078970  [u'Hindu Temple']  100699313239966093888   \n",
       "8707434     4399352  [u'Hindu Temple']  100699313239966093888   \n",
       "\n",
       "                   gPlusUserId  rating    reviewTime  unixReviewTime  \\\n",
       "8707432  104736345918291046305     4.0  Feb 10, 2013    1.360547e+09   \n",
       "8707433  106516869171611562978     5.0   Nov 2, 2013    1.383409e+09   \n",
       "8707434  107033935968639228641     5.0  Mar 24, 2013    1.364170e+09   \n",
       "\n",
       "                           name   Latitude  Longitude       categories_y  \\\n",
       "8707432  Gokarna Mahadev Temple  27.739403  85.387807  [u'Hindu Temple']   \n",
       "8707433  Gokarna Mahadev Temple  27.739403  85.387807  [u'Hindu Temple']   \n",
       "8707434  Gokarna Mahadev Temple  27.739403  85.387807  [u'Hindu Temple']   \n",
       "\n",
       "         placeIndex  userIndex  \n",
       "8707432       215.0     2981.0  \n",
       "8707433       215.0     4127.0  \n",
       "8707434       215.0     4477.0  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df[\"placeIndex\"]== 215]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do place pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get number of distinct categories in the full dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "897"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_to_place.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate rating for all users in train2**  (user : [[item,rating,time],[item,rating,time],[item,rating,time]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_pickle = open(\"/Users/studentuser/Downloads/Project/pickles/train2_asia.pickle\",\"rb\")\n",
    "train2 = pickle.load(train2_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a function to return the placeIndex for the given row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(x):\n",
    "    return merged_df_final.iloc[x,].placeIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Find the rating predictions for each user, this would be done as follows :**\n",
    "\n",
    "1. Compute the mean rating given by the user\n",
    "2. Find the places where the overall rating is above the mean rating given by the user\n",
    "3. Find the categories for all such places\n",
    "4. For each category from the categories above, find the place and if not visited by the user , add it t the contender places list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample code to check the working of geopy.distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.35290160386563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/studentuser/anaconda2/envs/mypython3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Vincenty is deprecated and is going to be removed in geopy 2.0. Use `geopy.distance.geodesic` (or the default `geopy.distance.distance`) instead, which is more accurate and always converges.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import geopy.distance\n",
    "\n",
    "coords_1 = (52.2296756, 21.0122287)\n",
    "coords_2 = (52.406374, 16.9251681)\n",
    "\n",
    "print(geopy.distance.vincenty(coords_1, coords_2).km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the user profile csv and get the location related information for each user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8777"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profile = pd.read_csv(\"/Users/studentuser/Downloads/Project/user_profiles_new.csv\")\n",
    "len(user_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "train1_asia = sparse.load_npz(\"/Users/studentuser/Downloads/Project/sparse_matrix_train1_asia.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "train1_time_asia = sparse.load_npz(\"/Users/studentuser/Downloads/Project/sparse_matrix_train1_time_asia.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_asia = open(\"/Users/studentuser/Downloads/Project/pickles/train2_asia.pickle\",\"rb\")\n",
    "train2_asia = pickle.load(train2_asia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_asia = open(\"/Users/studentuser/Downloads/Project/pickles/test_asia.pickle\",\"rb\")\n",
    "test_asia = pickle.load(test_asia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "train12_asia = sparse.load_npz(\"/Users/studentuser/Downloads/Project/sparse_matrix_train1_asia_trian1+train2.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "train12_time_asia = sparse.load_npz(\"/Users/studentuser/Downloads/Project/sparse_matrix_train1_time_asia_trian1+train2.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing  100  users\n",
      "Done processing  200  users\n",
      "Done processing  300  users\n",
      "Done processing  400  users\n",
      "Done processing  500  users\n",
      "Done processing  600  users\n",
      "Done processing  700  users\n",
      "Done processing  800  users\n",
      "Done processing  900  users\n",
      "Done processing  1000  users\n",
      "Done processing  1100  users\n",
      "Done processing  1200  users\n",
      "Done processing  1300  users\n",
      "Done processing  1400  users\n",
      "Done processing  1500  users\n",
      "Done processing  1600  users\n",
      "Done processing  1700  users\n",
      "Done processing  1800  users\n",
      "Done processing  1900  users\n",
      "Done processing  2000  users\n",
      "Done processing  2100  users\n",
      "Done processing  2200  users\n",
      "Done processing  2300  users\n",
      "Done processing  2400  users\n",
      "Done processing  2500  users\n",
      "Done processing  2600  users\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store mappings of user to list of (contender_place,distance)\n",
    "user_contender_dist = {}\n",
    "predict_global_mean = []\n",
    "predict_zero_rating = []\n",
    "predict_five_rating = []\n",
    "counter = 0\n",
    "for user,val in test_asia.items():\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(\"Done processing \" , counter , \" users\")\n",
    "    user_loc = tuple()\n",
    "    \n",
    "    if user in user_profile.index:\n",
    "        if not np.isnan(user_profile.loc[user][\"current_lat\"]):\n",
    "            user_loc = (user_profile.loc[user][\"current_lat\"],user_profile.loc[user][\"current_long\"])\n",
    "        elif not np.isnan(user_profile.loc[user][\"previous_lat\"]):\n",
    "            user_loc = (user_profile.loc[user][\"previous_lat\"],user_profile.loc[user][\"previous_long\"])\n",
    "\n",
    "    # First check if user location information is present, if not present then find the location of the most recently \n",
    "    # reviewed place and make that the user location\n",
    "    if len(user_loc) == 0:\n",
    "        if len(train12_time_asia.getrow(user).tocoo().data) > 0:\n",
    "            max_timestamp = 0\n",
    "            for j,v in zip(train12_time_asia.getrow(user).tocoo().col,train12_time_asia.getrow(user).tocoo().data):\n",
    "                if v > max_timestamp:\n",
    "                    latest_place = j\n",
    "            if latest_place in place_geodf.index:\n",
    "                user_loc = (place_geodf.loc[latest_place][\"Latitude\"],place_geodf.loc[latest_place][\"Longitude\"])\n",
    "        else:\n",
    "            # Such a user doesn't have any location or rating information and we would predict global mean for all\n",
    "            # places he visits in train2\n",
    "            predict_global_mean.append(user)\n",
    "\n",
    "\n",
    "\n",
    "    if len(user_loc) > 0:\n",
    "        # Check if user has some rating in train1_asia, if there are ratings then compute the mean of the ratings\n",
    "        # and then find the categories for which the user has rated the places above the mean rating\n",
    "        # if there are no ratings then the contender places would be the nearby places\n",
    "\n",
    "        contender_places = set()\n",
    "        if len(train12_asia.getrow(user).tocoo().data) > 0:\n",
    "\n",
    "            mean_rating_user = np.mean(train12_asia.getrow(user).tocoo().data)\n",
    "            places_above_mean = []\n",
    "            for j,v in zip(train12_asia.getrow(user).tocoo().col,train12_asia.getrow(user).tocoo().data):\n",
    "\n",
    "                if v > mean_rating_user - 0.2:\n",
    "                    places_above_mean.append(j)\n",
    "\n",
    "\n",
    "            for place in places_above_mean:\n",
    "                for cat in place_to_cat[place]:\n",
    "                    for contender_place in cat_to_place[cat]:\n",
    "                        if contender_place not in places_above_mean:\n",
    "                            contender_places.add(contender_place)\n",
    "                            \n",
    "                            \n",
    "            if len(contender_places) == 0:\n",
    "                predict_zero_rating.append(user)\n",
    "                            \n",
    "            elif len(contender_places) == 1:\n",
    "                predict_five_rating.append(user)\n",
    "                \n",
    "            else:\n",
    "                for place in contender_places:\n",
    "                    if place in place_geodf.index:\n",
    "                        if not np.isnan(place_geodf.loc[place][\"Latitude\"]):\n",
    "\n",
    "                            place_loc = (place_geodf.loc[place][\"Latitude\"] , place_geodf.loc[place][\"Longitude\"])\n",
    "                            dist = geopy.distance.geodesic(user_loc, place_loc ).km\n",
    "                            if user in user_contender_dist:\n",
    "                                user_contender_dist[user].append((place,dist))\n",
    "                            else:\n",
    "                                user_contender_dist[user] = []\n",
    "                                user_contender_dist[user].append((place,dist))\n",
    "            \n",
    "\n",
    "\n",
    "        else:\n",
    "            maxLat = user_loc[0] + 4\n",
    "            minLat = user_loc[0] - 4\n",
    "            maxLong = user_loc[1] + 4\n",
    "            minLong = user_loc[1] - 4\n",
    "            # add and subtract 2 to the lat long\n",
    "            fabricated_places = 0\n",
    "            for place in place_geodf.index:\n",
    "                if (place_geodf.loc[place][\"Latitude\"] < maxLat and place_geodf.loc[place][\"Latitude\"] > minLat) and \\\n",
    "                    (place_geodf.loc[place][\"Longitude\"] < maxLong and place_geodf.loc[place][\"Longitude\"] > minLong ):\n",
    "\n",
    "                    place_loc = (place_geodf.loc[place][\"Latitude\"] , place_geodf.loc[place][\"Longitude\"])\n",
    "                    dist = geopy.distance.geodesic(user_loc, place_loc ).km\n",
    "                    fabricated_places += 1\n",
    "                    if user in user_contender_dist:\n",
    "                        user_contender_dist[user].append((place,dist))\n",
    "                    else:\n",
    "                        user_contender_dist[user] = []\n",
    "                        user_contender_dist[user].append((place,dist))\n",
    "                        \n",
    "            if fabricated_places == 0:\n",
    "                predict_zero_rating.append(user)\n",
    "\n",
    "    #Normalize distances for each user and concert distances to rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Normalized Ratings for contender places using the computed distances**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the dictionary into cold start users and actual users**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print those users who have given a rating, but there are no contender places corresponding to the categories in which they gave the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in train2_asia.keys():\n",
    "    if user not in predict_global_mean and user not in predict_five_rating and user not in predict_zero_rating:\n",
    "        if user not in user_contender_dist.keys():\n",
    "            print(user)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_asia.getrow(58).tocoo().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check #1  : Check if the users in user_contender_dist have atleast two contender places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in user_contender_dist:\n",
    "    if len(user_contender_dist[user]) < 2:\n",
    "        print(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Normalized Ratings for contender places using the computed distances. This would be done for users who have greater than or equal to two contender places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_contender_preds = {}\n",
    "\n",
    "for user in user_contender_dist:\n",
    "    \n",
    "    \n",
    "    if user not in predict_global_mean and user not in predict_five_rating and user not in predict_zero_rating:\n",
    "        \n",
    "        contender_places = user_contender_dist[user]\n",
    "\n",
    "        if(len(contender_places) > 2):\n",
    "            max_dist = 0\n",
    "            for place in contender_places:\n",
    "                if place[1] > max_dist:\n",
    "                    max_dist = place[1]\n",
    "\n",
    "            min_dist = float('inf')\n",
    "            for place in contender_places:\n",
    "                if place[1] < min_dist:\n",
    "                    min_dist = place[1]\n",
    "\n",
    "            for place in contender_places:\n",
    "                score = ((place[1]-min_dist)/(max_dist-min_dist))\n",
    "                pred = (1-score)*5.0\n",
    "                user_contender_preds[(user,place[0])] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Global Mean Rating for a given sparse matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_item_rating = 0\n",
    "tot_item_count = 0\n",
    "for user, item, rating_here in zip(train12_asia.row, train12_asia.col, train12_asia.data):\n",
    "\n",
    "    tot_item_rating += rating_here\n",
    "    tot_item_count += 1\n",
    "    counter+=1\n",
    "\n",
    "\n",
    "    \n",
    "global_mean = tot_item_rating/tot_item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.000200226923847"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now go through the train2 data and make predictions and calculate RMSE\n",
    "final_preds = {}\n",
    "sum_rmse = 0\n",
    "N = 0\n",
    "for user,val in test_asia.items():\n",
    "    \n",
    "    if user in predict_global_mean:\n",
    "        for item in val:\n",
    "            N += 1\n",
    "            final_preds[(user,item[0])] = global_mean\n",
    "            sum_rmse += (global_mean - item[1])**2\n",
    "    elif user in predict_five_rating:\n",
    "        for item in val:\n",
    "            N += 1\n",
    "            final_preds[(user,item[0])] = 5.0\n",
    "            sum_rmse += (5 - item[1])**2\n",
    "    elif user in predict_zero_rating:\n",
    "        for item in val:\n",
    "            N += 1\n",
    "            final_preds[(user,item[0])] = 0  \n",
    "            sum_rmse += (item[1])**2\n",
    "    else:\n",
    "        for item in val:\n",
    "            N += 1\n",
    "            if (user,item[0]) in user_contender_preds:\n",
    "                prediction = user_contender_preds[(user,item[0])]\n",
    "                final_preds[(user,item[0])] = prediction\n",
    "                sum_rmse += (prediction - item[1])**2\n",
    "            else:\n",
    "                final_preds[(user,item[0])] = 0\n",
    "                sum_rmse += (item[1])**2\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.401714997765819"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sum_rmse/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content_based_preds_test_combined.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_preds_test_cold_start = {}\n",
    "content_based_preds_test_only = {}\n",
    "for key,val in final_preds.items():\n",
    "    if key[0] in predict_global_mean or key[0] in predict_zero_rating:\n",
    "        content_based_preds_test_cold_start[key] = val\n",
    "    else:\n",
    "        content_based_preds_test_only[key] = val\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content_based_preds_test_cold_start.pickle', 'wb') as handle:\n",
    "    pickle.dump(content_based_preds_test_cold_start, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content_based_preds_test_only.pickle', 'wb') as handle:\n",
    "    pickle.dump(content_based_preds_test_only, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.308427215577763"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sum_rmse/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove corrupt values of Latitude and Longitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(merged_df[(merged_df.Latitude < 10**7) & (merged_df.Latitude > 90)].index)\n",
    "merged_df = merged_df.drop(merged_df[(merged_df.Latitude > -10**7) & (merged_df.Latitude < -90)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18798"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a subset of lat-long that are corrupt but can be recovered**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_7 = merged_df.loc[(merged_df['Latitude'] >= 10**7) | (merged_df['Latitude'] <= -10**7)]\n",
    "merged_df_not_7 = merged_df.loc[~((merged_df['Latitude'] >= 10**7) | (merged_df['Latitude'] <= -10**7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_list = []\n",
    "lat_list = []\n",
    "long_list = []\n",
    "counter = 0\n",
    "for index,row in merged_df_7.iterrows():\n",
    "    if counter % 100 == 0:\n",
    "        print(\"Done with \" , counter,  \" rows\")\n",
    "    lat_list.append(float(row[\"Latitude\"])/(10**7))\n",
    "    long_list.append(float(row[\"Longitude\"])/(10**7))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_7[\"Latitude\"] = lat_list\n",
    "merged_df_7[\"Longitude\"] = long_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_final = pd.concat([merged_df_7, merged_df_not_7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using first and second mapping, create the final mapping for gplusUserId:userIndex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_gplus_old_pickle = open(\"/Users/studentuser/Downloads/Project/item_mapping_dict_from_category.pickle\",\"rb\")\n",
    "item_gplus_old_dict= pickle.load(item_gplus_old_pickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_gplus_old_pickle = open(\"/Users/studentuser/Downloads/Project/pickles/user_mapping_dict_from_category.pickle\",\"rb\")\n",
    "user_gplus_old_dict = pickle.load(user_gplus_old_pickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_old_new_pickle = open(\"/Users/studentuser/Downloads/Project/pickles/item_mapping_dict_from_category_old_new.pickle\",\"rb\")\n",
    "item_old_new_dict = pickle.load(item_old_new_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_old_new_pickle = open(\"/Users/studentuser/Downloads/Project/pickles/user_mapping_dict_old_new.pickle\",\"rb\")\n",
    "user_old_new_dict = pickle.load(user_old_new_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}\n",
    "item_dict = {}\n",
    "\n",
    "\n",
    "for item,val in item_gplus_old_dict.items():\n",
    "    if val in item_old_new_dict.keys():\n",
    "        item_dict[item] = item_old_new_dict[val]\n",
    "        \n",
    "for user,val in user_gplus_old_dict.items():\n",
    "    if val in user_old_new_dict.keys():\n",
    "        user_dict[user] = user_old_new_dict[val]\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
